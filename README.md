# BankSight-AI ğŸ¦ğŸ¤–

A simple, local-first AI banking assistant built with **FastAPI**, **HuggingFace Transformers**, and **Streamlit** - perfect for learning RAG and AI agents!

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688.svg)](https://fastapi.tiangolo.com)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.31-red.svg)](https://streamlit.io)
[![HuggingFace](https://img.shields.io/badge/HuggingFace-Transformers-yellow.svg)](https://huggingface.co/transformers/)

---

## ğŸ¯ What is This?

A **learning project** combining modern AI technologies:

âœ… **FastAPI Backend** - Professional REST API architecture
âœ… **HuggingFace Models** - Local LLMs (Phi-3, Mistral, Llama)
âœ… **Streamlit Frontend** - Beautiful, interactive chat UI
âœ… **RAG System** - Ask questions about uploaded documents
âœ… **AI Agent** - Perform banking actions via natural language
âœ… **100% Local** - No cloud, no API costs, completely private

**Perfect for:** Learning RAG, AI agents, FastAPI, and local LLM deployment

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit     â”‚  â† Beautiful chat UI
â”‚   Frontend      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP REST API
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI       â”‚  â† RESTful backend
â”‚   Backend       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
    â”‚          â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  RAG   â”‚ â”‚ Actions â”‚
â”‚ System â”‚ â”‚ Handler â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
    â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ChromaDBâ”‚ â”‚  Dummy  â”‚
â”‚(Vector)â”‚ â”‚  Data   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LLM: HuggingFace Phi-3/Mistral/Llama
```

**Clean separation** of frontend, backend, RAG, and actions!

---

## ğŸŒŸ Features

### 1. Document Q&A (RAG)
Upload PDFs, TXT, DOCX and ask questions:
```
You: "What are the wire transfer fees?"
AI: "According to the banking policy:
     - Domestic: $25
     - International: $45
     [Source: banking_policy.txt]"
```

### 2. Banking Actions
Interact with dummy data:
```
You: "What's my balance?"
AI: "Your checking account (****1234) has $5,430.50"

You: "Transfer $100 to savings"
AI: "âœ… Transfer completed! New balance: $5,330.50"
```

### 3. Smart Agent
- Classifies intent (question vs action)
- Routes to appropriate handler
- Maintains conversation context
- Provides sourced answers

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- 8GB+ RAM (16GB recommended)
- 10GB free disk space

### Installation

```bash
# 1. Clone repository
git clone <your-repo>
cd BankSight-AI

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Done! Models will download on first run.
```

### Running the App

**Two terminals needed:**

**Terminal 1: Start Backend**
```bash
./run_backend.sh
# Or manually: python -m uvicorn backend.main:app --reload
```

**Terminal 2: Start Frontend**
```bash
./run_frontend.sh
# Or manually: streamlit run frontend/app.py
```

**Access:**
- ğŸŒ **Frontend:** http://localhost:8501
- ğŸ”§ **API Docs:** http://localhost:8000/docs
- â¤ï¸ **Health Check:** http://localhost:8000/health

### First Use

1. **Process Documents:** Click "Process All Documents" in sidebar
2. **Ask a Question:** "What are the account opening requirements?"
3. **Try an Action:** "What is my account balance?"

---

## ğŸ“ Project Structure

```
BankSight-AI/
â”œâ”€â”€ backend/                    # FastAPI Backend
â”‚   â”œâ”€â”€ main.py                # API entry point
â”‚   â”œâ”€â”€ config.py              # Configuration
â”‚   â”œâ”€â”€ agent/                 # AI Agent
â”‚   â”‚   â”œâ”€â”€ agent.py          # Main orchestrator
â”‚   â”‚   â”œâ”€â”€ intent_classifier.py
â”‚   â”‚   â””â”€â”€ query_router.py
â”‚   â”œâ”€â”€ llm/                   # HuggingFace LLM
â”‚   â”‚   â”œâ”€â”€ huggingface_client.py
â”‚   â”‚   â””â”€â”€ prompts.py
â”‚   â”œâ”€â”€ rag/                   # RAG System
â”‚   â”‚   â”œâ”€â”€ document_loader.py
â”‚   â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â””â”€â”€ retriever.py
â”‚   â””â”€â”€ actions/               # Banking Actions
â”‚       â”œâ”€â”€ banking_data.py
â”‚       â””â”€â”€ banking_actions.py
â”‚
â”œâ”€â”€ frontend/                   # Streamlit Frontend
â”‚   â”œâ”€â”€ app.py                 # Main UI
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ api_client.py      # Backend client
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/             # Upload docs here
â”‚   â”œâ”€â”€ banking_dummy_data.json
â”‚   â””â”€â”€ vector_db/             # ChromaDB storage
â”‚
â”œâ”€â”€ config.yaml                # Configuration
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ run_backend.sh            # Start backend
â””â”€â”€ run_frontend.sh           # Start frontend
```

**Only ~25 Python files** - easy to understand!

---

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Backend** | FastAPI | REST API, async support |
| **Frontend** | Streamlit | Interactive chat UI |
| **LLM** | HuggingFace Transformers | Local inference |
| **Embeddings** | Sentence-Transformers | Text embeddings |
| **Vector DB** | ChromaDB | Semantic search |
| **Data** | JSON | Dummy banking data |

**All open-source & free!**

---

## âš™ï¸ Configuration

Edit `config.yaml` to customize:

### LLM Models (Choose based on your hardware)

```yaml
llm:
  # Options:
  model_name: "microsoft/Phi-3-mini-4k-instruct"  # 8GB RAM
  # model_name: "mistralai/Mistral-7B-Instruct-v0.2"  # 16GB RAM
  # model_name: "meta-llama/Llama-3-8B-Instruct"  # 18GB RAM
```

### RAG Settings

```yaml
rag:
  chunk_size: 500        # Chunk size in characters
  chunk_overlap: 50      # Overlap between chunks
  top_k: 5               # Number of chunks to retrieve
```

---

## ğŸ’¡ Usage Examples

### Document Q&A
1. Upload a PDF in the sidebar
2. Click "Upload & Process"
3. Ask: "What are the fees for wire transfers?"

### Banking Actions
- "What is my checking account balance?"
- "Show my last 10 transactions"
- "Transfer $50 from checking to savings"
- "Search for grocery transactions"

### Follow-up Questions
```
You: "What are the wire transfer fees?"
AI: [Explains fees]

You: "What about international?"
AI: [Remembers context, answers specifically]
```

---

## ğŸ”§ API Endpoints

Full API docs at http://localhost:8000/docs

**Main Endpoints:**
```
POST   /api/chat                 # Send message
POST   /api/documents/upload     # Upload document
GET    /api/documents            # List documents
POST   /api/documents/process-all  # Process all docs
GET    /health                   # Health check
```

---

## ğŸ§ª Testing

```bash
# Start backend
./run_backend.sh

# In another terminal
python -m pytest tests/
```

---

## ğŸ“Š System Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| RAM | 8GB | 16GB+ |
| Disk | 10GB | 20GB+ |
| CPU | 4 cores | 8+ cores |
| GPU | Not required | Speeds up inference |

**Models:**
- Phi-3-mini: ~4GB download, ~8GB RAM
- Mistral-7B: ~4GB download, ~16GB RAM
- Llama-3-8B: ~5GB download, ~18GB RAM

---

## ğŸ› Troubleshooting

### Backend won't start
```bash
# Check if port 8000 is in use
lsof -i :8000  # Mac/Linux
netstat -ano | findstr :8000  # Windows

# Try different port
uvicorn backend.main:app --port 8001
```

### Out of memory
- Use Phi-3-mini instead of Mistral/Llama
- Set `load_in_8bit: true` in config.yaml
- Close other applications

### Slow inference
- First generation is always slow (model loading)
- Use GPU if available
- Reduce `max_new_tokens` in config

### Documents not found
- Click "Process All Documents" in sidebar
- Check `data/documents/` directory exists
- Verify file formats (PDF, TXT, DOCX supported)

---

## ğŸ“š Learning Resources

### RAG
- [ChromaDB Docs](https://docs.trychroma.com/)
- [Sentence-Transformers](https://www.sbert.net/)
- [RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/)

### HuggingFace
- [Transformers Docs](https://huggingface.co/docs/transformers/)
- [Model Hub](https://huggingface.co/models)
- [Phi-3 Model Card](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)

### FastAPI
- [FastAPI Tutorial](https://fastapi.tiangolo.com/tutorial/)
- [Async Programming](https://fastapi.tiangolo.com/async/)

### Streamlit
- [Streamlit Docs](https://docs.streamlit.io/)
- [Chat Elements](https://docs.streamlit.io/library/api-reference/chat)

---

## ğŸ“ What You'll Learn

Completing this project teaches:

### Technical Skills
âœ… Building REST APIs with FastAPI
âœ… Working with local LLMs (HuggingFace)
âœ… Implementing RAG (retrieval-augmented generation)
âœ… Vector databases and semantic search
âœ… AI agent patterns (intent classification, routing)
âœ… Frontend/backend separation
âœ… Document processing pipelines

### Best Practices
âœ… Project structure and organization
âœ… Configuration management
âœ… Error handling
âœ… Logging and debugging
âœ… Testing strategies

---

## ğŸš§ Roadmap

- [x] FastAPI backend
- [x] Streamlit frontend
- [x] RAG system with ChromaDB
- [x] HuggingFace LLM integration
- [x] Banking actions on dummy data
- [x] Intent classification
- [ ] Conversation memory
- [ ] More file types (Excel, images)
- [ ] Response streaming
- [ ] Model fine-tuning guide

---

## ğŸ¤ Contributing

Contributions welcome! This is a learning project.

Ideas for improvements:
- Better intent classification
- More banking actions
- UI enhancements
- Additional document types
- Performance optimizations

---

## ğŸ“„ License

MIT License - Free to use, modify, and learn from!

---

## ğŸ™ Acknowledgments

- **HuggingFace** - Amazing open-source models
- **FastAPI** - Modern Python web framework
- **Streamlit** - Beautiful Python UIs
- **ChromaDB** - Simple vector database
- **Sentence-Transformers** - Excellent embeddings

---

## ğŸ“ Questions?

- Check [QUICK_START.md](QUICK_START.md) for detailed setup
- See [ARCHITECTURE.md](ARCHITECTURE.md) for system design
- See [PROJECT_PLAN.md](PROJECT_PLAN.md) for learning roadmap

---

**Built with â¤ï¸ for learning AI, RAG, and agents**

**Stack:** FastAPI + HuggingFace + Streamlit | **Cost:** $0 | **Privacy:** 100% Local
