# Backend - FastAPI
fastapi
uvicorn[standard]
pydantic>=2.0  # v2.x required (breaking changes from v1.x)
pydantic-settings
python-multipart

# LLM - Groq API (Cloud Inference)
groq  # Fast cloud inference via Groq API

# RAG - Vector Database & Embeddings (CPU-compatible)
chromadb>=0.4  # v0.4+ has improved API
sentence-transformers  # For embeddings (works on CPU)

# Frontend - Streamlit
streamlit

# Document Processing
pypdf2
pdfplumber
python-docx
pandas

# Utilities
pyyaml
python-dotenv
requests
httpx
aiofiles

# Development (Optional)
jupyter
ipykernel
pytest
pytest-asyncio
black

# ==========================================
# OPTIONAL: Local Model Support (HuggingFace)
# ==========================================
# Uncomment the lines below ONLY if you want to use local models as fallback
# This requires significantly more resources and is not needed for Groq API

# transformers>=4.38.0
# torch>=2.0
# accelerate
# sentencepiece
# protobuf

# For 8-bit/4-bit quantization (GPU only):
# bitsandbytes
